# -*- coding: utf-8 -*-
"""Book_Recommendations_LLM_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nKMCU1UA5ufI8iKvBjj5vHtSgF6CxMg-
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("dylanjcastillo/7k-books-with-metadata")

print("Path to dataset files:", path)

import pandas as pd

books = pd.read_csv(f'{path}/books.csv')
books.head(20)

books.info()

books.isna().sum()

#inspecting missing values with matplotlib and seaborn

import matplotlib.pyplot as plt
import seaborn as sns

ax = plt.axes()
sns.heatmap(books.isna().transpose(),cbar = False,ax = ax)
plt.xlabel("missing")
plt.ylabel("books")
plt.show()

import numpy as np

books["missing_describtion"]  = np.where(books["description"].isna(),1,0)
books["age_of_book"] = 2025 - books["published_year"]

columns_of_interest = ["num_pages","ratings_count","age_of_book","missing_describtion"]

corelation_matrix = books[columns_of_interest].corr(method= "spearman")
heatmap = sns.heatmap(corelation_matrix,annot=True,cbar = "coolwarm",cbar_kws={"label":"spearman correlation"})
heatmap.set_title("heatmap_correlation")
plt.figure(figsize=(8,6))
plt.show()

book_missing = books[~(books["description"].isna()) & (~books["num_pages"].isna()) & (~books["ratings_count"].isna()) & (~books["age_of_book"].isna())]
book_missing

book_missing['categories'].value_counts().reset_index(drop=True).sort_values(ascending=False)

book_missing["word_of_description"] = book_missing["description"].str.split().str.len()
#sns.barplot(book_missing["word_of_description"].sort_values(ascending=True))
#plt.figure(figsize=(8,6))
#plt.show()

book_missing.loc[book_missing["word_of_description"].between(1,4),"description"]

book_missing_25_words=book_missing[book_missing["word_of_description"]>=25]
book_missing_25_words

book_missing_25_words["title_and_subtitle"] = (np.where(book_missing_25_words["subtitle"].isna(),book_missing_25_words["title"],book_missing_25_words["title"] + " " + book_missing_25_words["subtitle"]))

book_missing_25_words["tagged_description"] = book_missing_25_words[["isbn13","description"]].astype(str).agg(" ".join,axis=1)
book_missing_25_words

(
    book_missing_25_words.drop(["subtitle","missing_describtion","age_of_book","word_of_description"],axis =1).to_csv("books_cleaned.csv",index=False)
)

pip install langchain

pip install langchain_community

pip install langchain_openai

pip install openai

import os
os.environ["OPENAI_API_KEY"] ="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"

pip install chromadb

pip install langchain-chroma

import pandas as pd

books = pd.read_csv("books_cleaned.csv")
books

books['tagged_description']

import pandas as pd
import time

from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

#for textLoader
books['tagged_description'].to_csv("tagged_description.txt", index=False,header=False,sep='\n')

raw_documents = TextLoader("tagged_description.txt").load()
text_splitter = CharacterTextSplitter(chunk_size = 0,chunk_overlap =0,separator = '\n')
documents = text_splitter.split_documents(raw_documents)

documents[0]

import os

os.environ["OPENAI_API_KEY"] = "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"  # from groq.com
os.environ["OPENAI_API_BASE"] = "https://api.groq.com/openai/v1"

embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

chroma_db = Chroma.from_documents(documents, embedding_model)

retriever = chroma_db.as_retriever()

qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="llama3-8b-8192", temperature=0),  # model must be supported by GROQ
    retriever=retriever,
    return_source_documents=True
)

# STEP 7: Ask a question
query = "What is a common theme among the books?"
result = qa_chain(query)
print(result['result'])

def generate_response(
    str:str,
    top_k =10
)->pd.DataFrame:
   recs = chroma_db.similarity_search(str,k=top_k)
   book_list =[]
   for rec in recs:
    book_list += [int(recs.page_content.strip('"').split()[0])]
   return books[books["isbn13"].isin(book_list)]

#Test Classification using LLM with Zero Shot Classification

import pandas as pd

books = pd.read_csv("books_cleaned.csv")

books["categories"].value_counts().reset_index()

category_mapping = {'Fiction' : "Fiction",
 'Juvenile Fiction': "Children's Fiction",
 'Biography & Autobiography': "Nonfiction",
 'History': "Nonfiction",
 'Literary Criticism': "Nonfiction",
 'Philosophy': "Nonfiction",
 'Religion': "Nonfiction",
 'Comics & Graphic Novels': "Fiction",
 'Drama': "Fiction",
 'Juvenile Nonfiction': "Children's Nonfiction",
 'Science': "Nonfiction",
 'Poetry': "Fiction"}

books["simple_categories"] = books["categories"].map(category_mapping)

books[~(books["simple_categories"].isna())]

from transformers import pipeline

fiction_categories = ["Fiction", "Nonfiction"]

pipe = pipeline("zero-shot-classification",
                model="facebook/bart-large-mnli",
                )

sequence = books.loc[books["simple_categories"] == "Fiction", "description"].reset_index(drop=True)[0]

pipe(sequence, fiction_categories)





